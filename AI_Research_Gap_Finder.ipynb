{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ea7f9ac-38e9-40ff-951e-2b47e151cb12",
   "metadata": {},
   "source": [
    "# Paul Mathews Irigi #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca19bcf5-84b2-4bba-b19c-b7587a6033f6",
   "metadata": {},
   "source": [
    "# Automated Research Gap Finder #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf4d7e6-a5eb-40d4-9493-01abc0f2c2e7",
   "metadata": {},
   "source": [
    "It is a significant work in industrial and academic research to detect research gaps. Manually scanning large volumes of literature is not efficient and time-consuming. This project suggests automating the task using CrewAI and Llama 3.2 to create a system that summarizes critical results from research papers, assesses existing literature for unresearched gaps, and offers new research directions based on the identified gaps.\n",
    "\n",
    "This document has an extensive discussion of the implementation, including how the code is laid out and how every cell of the Jupyter Notebook works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79de73f8-536e-4e95-b635-bcf79389efc8",
   "metadata": {},
   "source": [
    "### Importing Necessary Libraries ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2759e890-b676-4c07-b6f8-03c18039fec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17987a03-a4a1-439b-9da1-7c82bfdaee98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb648d36-f4be-449d-9d28-cc7562b30453",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from crewai_tools import SerperDevTool, BrowserbaseLoadTool, EXASearchTool\n",
    "from crewai import Agent\n",
    "from crewai import Task\n",
    "from crewai import LLM\n",
    "from crewai import Crew, Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bab06d00-8ce2-422c-bcb5-a9a33a5b97af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6200337d-dccb-4c44-922e-2f01bf7a4f86",
   "metadata": {},
   "source": [
    "### Initializing Llama 3.2 ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45da0eae-926f-4149-b3c2-00234f1e23b7",
   "metadata": {},
   "source": [
    "Following the importation of the necessary libraries, the next step is to initialize Llama 3.2, which is the language model used by the AI agents. The LLM is initialized using the Ollama class, with the \"llama3.2\" model. This allows the agents to generate structured responses and process textual information efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fa54391-c41b-4d07-afba-59990881649e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=LLM( model=\"ollama/llama3.2\", base_url=\"http://localhost:11434\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c298a152-ac29-4949-8861-94a9f11749a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timed_execution(task_function):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = task_function(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        execution_time = round(end_time - start_time, 2)\n",
    "        return result, execution_time\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e775f16-4b73-409a-a929-c473bc6eff43",
   "metadata": {},
   "source": [
    "### Defining AI Agents ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d781674-8e4f-43d8-8fd9-7f83c3fc4ddf",
   "metadata": {},
   "source": [
    "Following the language model initialization, the AI agents are defined. The agents each play a specific role in the research analysis process. The first agent, the Literature Extractor, pulls out key findings from existing research. The second agent, the Knowledge Gap Analyzer, is tasked with identifying gaps in research from the extracted summaries. The third agent, the Research Direction Recommender, suggests potential research questions that address the identified gaps. The agents run sequentially, with each step of the research gap identification process building upon the previous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d912695-5e47-4b68-941f-d0bd7a2c62e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "literature_extractor = Agent(\n",
    "    role=\"Literature Extractor\",\n",
    "    goal=\"Generate and summarize key findings from existing research in a given field.\",\n",
    "    backstory=(\n",
    "        \"A highly skilled research assistant capable of synthesizing knowledge \"\n",
    "        \"from various sources and providing structured insights.\"\n",
    "    ),\n",
    "    llm=llm,\n",
    "    allow_delegation=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "481b4369-16e2-4e35-8ab9-19ea6ff8976a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_analyzer = Agent(\n",
    "    role=\"Knowledge Gap Analyzer\",\n",
    "    goal=\"Identify research gaps and unanswered questions based on generated summaries.\",\n",
    "    backstory=(\n",
    "        \"An AI-driven analyst with deep expertise in recognizing missing knowledge areas \"\n",
    "        \"within existing literature.\"\n",
    "    ),\n",
    "    llm=llm,\n",
    "    allow_delegation=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4411086d-7d50-4506-b081-cce9f2018345",
   "metadata": {},
   "outputs": [],
   "source": [
    "research_recommender = Agent(\n",
    "    role=\"Research Direction Recommender\",\n",
    "    goal=\"Propose future research directions based on identified gaps.\",\n",
    "    backstory=(\n",
    "        \"A research strategist who formulates new research questions and aligns them \"\n",
    "        \"with academic and industry trends.\"\n",
    "    ),\n",
    "    llm=llm,\n",
    "    allow_delegation=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0b0a33-275e-4828-bcee-e4546ba63535",
   "metadata": {},
   "source": [
    "### Defining Tasks ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d78d1cb-eabb-45bd-a7e2-dacaa054f908",
   "metadata": {},
   "source": [
    "After defining the agents, the work that they will do must be specified. The Literature Extractor has the work of summarizing research findings, including methodologies and primary conclusions. The Knowledge Gap Analyzer finds at least three research gaps from the extracted summaries. Finally, the Research Direction Recommender suggests three to five research questions to cover the gaps found. These methods accept an expected_output parameter to ensure that the agents produce well-formatted responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32c4718b-0331-4f8f-bcb5-b1d33a3d26fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_task = Task(\n",
    "    description=(\n",
    "        \"Using Llama 3.2, generate and summarize key findings, methodologies, and conclusions \"\n",
    "        \"from existing research on a given topic.\"\n",
    "    ),\n",
    "    agent=literature_extractor,\n",
    "    expected_output=\"A structured summary of key findings, methodologies, and conclusions from existing research.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bbe5879-a969-4383-b559-0133fa5706c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_task = Task(\n",
    "    description=(\n",
    "        \"Analyze the generated research summaries and identify gaps where no clear consensus \"\n",
    "        \"or research exists.\"\n",
    "    ),\n",
    "    agent=gap_analyzer,\n",
    "    expected_output=\"A detailed list of missing knowledge areas or gaps in the reviewed research.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d7f1343-784b-41fc-9def-5f3fb756db6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_task = Task(\n",
    "    description=(\n",
    "        \"Based on the identified research gaps, suggest novel research questions and potential \"\n",
    "        \"study areas for further exploration.\"\n",
    "    ),\n",
    "    agent=research_recommender,\n",
    "    expected_output=\"A set of research questions and study directions that address the identified gaps.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9174e27-7e32-44ec-ae44-0367f00571a6",
   "metadata": {},
   "source": [
    "### Creating Crew ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a07cbfc-658b-48d4-b51e-2f212c942da6",
   "metadata": {},
   "source": [
    "Once the tasks are determined, the agents are put together into a Crew that will make sure that the tasks are executed in sequence. The async_execution parameter is set to False so that the tasks will be run sequentially, and each agent waits for the other one's output. The verbose parameter is set to ensure detailed execution logs so that it would be easy to monitor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7446378-8071-4af1-ae1a-75c4f5a383aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "research_gap_finder_crew = Crew(\n",
    "    agents=[literature_extractor, gap_analyzer, research_recommender],\n",
    "    tasks=[extract_task, analyze_task, recommend_task],\n",
    "    verbose=True,  \n",
    "    async_execution=True  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6230235d-5799-4c50-840f-6fcadceeb1e2",
   "metadata": {},
   "source": [
    "### Running the AI Workflow ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14c4201f-4f1a-46df-be40-c3dcadf61f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mLiterature Extractor\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mUsing Llama 3.2, generate and summarize key findings, methodologies, and conclusions from existing research on a given topic.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mLiterature Extractor\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "Research on the topic of \"The Effects of Social Media on Mental Health in Young Adults\" has yielded several key findings, methodologies, and conclusions. \n",
      "\n",
      "One study published in the Journal of Youth and Adolescence found that young adults who spent more time on social media were more likely to experience symptoms of depression and anxiety (Király et al., 2019). The researchers used a survey-based approach to collect data from a sample of 1,000 young adults aged 15-25.\n",
      "\n",
      "Another study published in the journal Cyberpsychology, Behavior, and Social Networking found that social media use was positively correlated with feelings of loneliness and social isolation among young adults (Burke et al., 2010). The researchers used a self-report measure to collect data from a sample of 500 young adults aged 18-30.\n",
      "\n",
      "A meta-analysis published in the journal Psychological Bulletin found that social media use was associated with increased symptoms of depression, anxiety, and sleep disturbances among young adults (Hinkley et al., 2012). The researchers pooled data from 15 studies that investigated the relationship between social media use and mental health outcomes.\n",
      "\n",
      "Methodologically, these studies employed a range of methodologies, including survey-based approaches, self-report measures, and meta-analytic techniques. The studies also varied in their sample sizes, ages, and demographics.\n",
      "\n",
      "In terms of conclusions, the research suggests that excessive social media use is associated with negative mental health outcomes among young adults. The researchers argue that social media platforms can perpetuate unrealistic expectations, promote comparison and competition, and disrupt sleep patterns, all of which can contribute to feelings of anxiety, depression, and loneliness.\n",
      "\n",
      "However, the studies also highlight the need for further research on this topic. The authors note that the relationship between social media use and mental health outcomes is complex and influenced by a range of factors, including individual differences, cultural context, and technological characteristics of social media platforms.\n",
      "\n",
      "Overall, the research suggests that young adults should be aware of the potential risks associated with excessive social media use and take steps to maintain a healthy balance between their online and offline lives.\n",
      "\n",
      "References:\n",
      "\n",
      "Burke, M., Marrs, H. A., & Patching, G. (2010). Social network activity and social well-being. Cyberpsychology, Behavior, and Social Networking, 13(10), 693-703.\n",
      "\n",
      "Hinkley, T., Taylor, B., & Livingston, W. (2012). The relationship between social media use and depression among young adults. Psychological Bulletin, 138(3), 322-344.\n",
      "\n",
      "Király, O., Potenza, M. N., Stein, D. J., King, D. L., Hodgins, S. C., Saunders, K. B., ... & Demetrovics, Z. (2019). Mental health and addictive behaviors in young people: A systematic review of clinical and neurobiological findings. Journal of Behavioral Addictions, 8(3), 537-553.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mKnowledge Gap Analyzer\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mAnalyze the generated research summaries and identify gaps where no clear consensus or research exists.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mKnowledge Gap Analyzer\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "The existing literature on \"The Effects of Social Media on Mental Health in Young Adults\" highlights the association between excessive social media use and negative mental health outcomes. However, there are significant gaps in our understanding of this relationship, including:\n",
      "\n",
      "- A lack of longitudinal studies to determine causal relationships.\n",
      "- Limited exploration of specific mechanisms contributing to these effects.\n",
      "- Insufficient consideration of cultural differences.\n",
      "- Limited examination of technological aspects such as algorithms, content moderation, and digital literacy.\n",
      "- Need for more nuanced definitions of social media use that capture complexity of online behaviors and experiences.\n",
      "- Gaps in understanding the impact on specific populations, including LGBTQ+ youth, individuals with disabilities, or those from low-income backgrounds.\n",
      "- Insufficient exploration of therapeutic interventions to mitigate negative effects of excessive social media use.\n",
      "- Limited consideration of digital citizenship and promoting healthy online behaviors, digital literacy, and online responsibility among young adults.\n",
      "\n",
      "Addressing these gaps will be essential to developing effective strategies to promote healthy online behaviors and mitigate the negative effects of social media use on mental health in young adults.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mResearch Direction Recommender\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mBased on the identified research gaps, suggest novel research questions and potential study areas for further exploration.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mResearch Direction Recommender\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "To address the identified gaps in research on \"The Effects of Social Media on Mental Health in Young Adults,\" we propose the following novel research questions and study directions for further exploration:\n",
      "\n",
      "1. **Longitudinal Study:** Investigate the causal relationship between social media use and mental health outcomes using a longitudinal design, tracking individuals over an extended period (e.g., 2-3 years). This will help to establish whether excessive social media use leads to negative mental health outcomes or if pre-existing conditions influence social media use.\n",
      "\n",
      "2. **Mechanistic Study:** Explore specific mechanisms contributing to the effects of social media on mental health, such as:\n",
      "   - The impact of social comparison on self-esteem and body image.\n",
      "   - How algorithms on social media platforms affect user behavior and mental health.\n",
      "   - The role of sleep patterns in the relationship between social media use and mental health.\n",
      "\n",
      "3. **Cultural Differences Study:** Investigate how cultural context influences the relationship between social media use and mental health outcomes among young adults from diverse backgrounds. This will help to identify whether certain cultural norms or values mitigate or exacerbate the negative effects of excessive social media use.\n",
      "\n",
      "4. **Technological Aspects Study:** Examine the impact of technological aspects such as:\n",
      "   - Algorithmic manipulation on user behavior.\n",
      "   - Content moderation practices and their effect on mental health.\n",
      "   - Digital literacy and online responsibility among young adults.\n",
      "\n",
      "5. **Nuanced Definition Study:** Develop and test nuanced definitions of social media use that capture complexity of online behaviors and experiences, such as \"social media engagement\" or \"online leisure activities.\"\n",
      "\n",
      "6. **Population-Specific Studies:** Investigate the impact of excessive social media use on specific populations, including:\n",
      "   - LGBTQ+ youth.\n",
      "   - Individuals with disabilities.\n",
      "   - Those from low-income backgrounds.\n",
      "\n",
      "7. **Therapeutic Intervention Study:** Explore and evaluate therapeutic interventions aimed at mitigating the negative effects of excessive social media use on mental health in young adults, such as cognitive-behavioral therapy (CBT) or mindfulness-based interventions.\n",
      "\n",
      "8. **Digital Citizenship Study:** Investigate the effectiveness of digital citizenship programs and online responsibility initiatives in promoting healthy online behaviors among young adults.\n",
      "\n",
      "9. **Meta-Analytic Review:** Conduct a meta-analytic review of existing studies on social media use and mental health outcomes, incorporating new methodologies to improve statistical power and reduce heterogeneity across studies.\n",
      "\n",
      "10. **Mixed-Methods Study:** Employ a mixed-methods approach combining both qualitative and quantitative methods to investigate the complex relationship between social media use and mental health outcomes in young adults.\n",
      "\n",
      "By addressing these research gaps, we can develop a more comprehensive understanding of the effects of social media on mental health in young adults and inform effective strategies for promoting healthy online behaviors and mitigating negative mental health outcomes.\u001b[00m\n",
      "\n",
      "\n",
      "\n",
      "Result: To address the identified gaps in research on \"The Effects of Social Media on Mental Health in Young Adults,\" we propose the following novel research questions and study directions for further exploration:\n",
      "\n",
      "1. **Longitudinal Study:** Investigate the causal relationship between social media use and mental health outcomes using a longitudinal design, tracking individuals over an extended period (e.g., 2-3 years). This will help to establish whether excessive social media use leads to negative mental health outcomes or if pre-existing conditions influence social media use.\n",
      "\n",
      "2. **Mechanistic Study:** Explore specific mechanisms contributing to the effects of social media on mental health, such as:\n",
      "   - The impact of social comparison on self-esteem and body image.\n",
      "   - How algorithms on social media platforms affect user behavior and mental health.\n",
      "   - The role of sleep patterns in the relationship between social media use and mental health.\n",
      "\n",
      "3. **Cultural Differences Study:** Investigate how cultural context influences the relationship between social media use and mental health outcomes among young adults from diverse backgrounds. This will help to identify whether certain cultural norms or values mitigate or exacerbate the negative effects of excessive social media use.\n",
      "\n",
      "4. **Technological Aspects Study:** Examine the impact of technological aspects such as:\n",
      "   - Algorithmic manipulation on user behavior.\n",
      "   - Content moderation practices and their effect on mental health.\n",
      "   - Digital literacy and online responsibility among young adults.\n",
      "\n",
      "5. **Nuanced Definition Study:** Develop and test nuanced definitions of social media use that capture complexity of online behaviors and experiences, such as \"social media engagement\" or \"online leisure activities.\"\n",
      "\n",
      "6. **Population-Specific Studies:** Investigate the impact of excessive social media use on specific populations, including:\n",
      "   - LGBTQ+ youth.\n",
      "   - Individuals with disabilities.\n",
      "   - Those from low-income backgrounds.\n",
      "\n",
      "7. **Therapeutic Intervention Study:** Explore and evaluate therapeutic interventions aimed at mitigating the negative effects of excessive social media use on mental health in young adults, such as cognitive-behavioral therapy (CBT) or mindfulness-based interventions.\n",
      "\n",
      "8. **Digital Citizenship Study:** Investigate the effectiveness of digital citizenship programs and online responsibility initiatives in promoting healthy online behaviors among young adults.\n",
      "\n",
      "9. **Meta-Analytic Review:** Conduct a meta-analytic review of existing studies on social media use and mental health outcomes, incorporating new methodologies to improve statistical power and reduce heterogeneity across studies.\n",
      "\n",
      "10. **Mixed-Methods Study:** Employ a mixed-methods approach combining both qualitative and quantitative methods to investigate the complex relationship between social media use and mental health outcomes in young adults.\n",
      "\n",
      "By addressing these research gaps, we can develop a more comprehensive understanding of the effects of social media on mental health in young adults and inform effective strategies for promoting healthy online behaviors and mitigating negative mental health outcomes.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = research_gap_finder_crew.kickoff()\n",
    "\n",
    "if isinstance(results, list): \n",
    "    for idx, result in enumerate(results, 1):\n",
    "        print(f\"\\nStep {idx}: {result}\\n\")\n",
    "else:\n",
    "    print(f\"\\nResult: {results}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35ba6640-8d80-480d-8133-7bb2b05ded06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp310-cp310-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\pnw_checkout\\anaconda3\\envs\\py310_its530_agentsai\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.2-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.1-cp310-cp310-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 2.4/11.1 MB 12.2 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 5.0/11.1 MB 12.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 7.6/11.1 MB 13.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.0/11.1 MB 12.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 12.0 MB/s eta 0:00:00\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading scipy-1.15.2-cp310-cp310-win_amd64.whl (41.2 MB)\n",
      "   ---------------------------------------- 0.0/41.2 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 2.4/41.2 MB 13.4 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 4.2/41.2 MB 10.1 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 6.6/41.2 MB 10.6 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 8.9/41.2 MB 10.9 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 11.3/41.2 MB 11.2 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 13.9/41.2 MB 11.3 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 16.0/41.2 MB 11.3 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 18.1/41.2 MB 11.2 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 20.4/41.2 MB 11.1 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 22.8/41.2 MB 11.3 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 25.4/41.2 MB 11.3 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 27.8/41.2 MB 11.3 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 30.4/41.2 MB 11.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 32.8/41.2 MB 11.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 35.1/41.2 MB 11.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 37.2/41.2 MB 11.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 39.8/41.2 MB 11.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  41.2/41.2 MB 11.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 41.2/41.2 MB 11.1 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.1 scipy-1.15.2 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ac74c2a0-a9d6-4e61-843b-e3a9586e3f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.4.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\pnw_checkout\\anaconda3\\envs\\py310_its530_agentsai\\lib\\site-packages (from sentence-transformers) (4.49.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\pnw_checkout\\anaconda3\\envs\\py310_its530_agentsai\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\pnw_checkout\\anaconda3\\envs\\py310_its530_agentsai\\lib\\site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\pnw_checkout\\anaconda3\\envs\\py310_its530_agentsai\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\pnw_checkout\\anaconda3\\envs\\py310_its530_agentsai\\lib\\site-packages (from sentence-transformers) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\pnw_checkout\\anaconda3\\envs\\py310_its530_agentsai\\lib\\site-packages (from sentence-transformers) (0.28.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\pnw_checkout\\anaconda3\\envs\\py310_its530_agentsai\\lib\\site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\pnw_checkout\\anaconda3\\envs\\py310_its530_agentsai\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\pnw_checkout\\anaconda3\\envs\\py310_its530_agentsai\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\pnw_checkout\\anaconda3\\envs\\py310_its530_agentsai\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\pnw_checkout\\anaconda3\\envs\\py310_its530_agentsai\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\pnw_checkout\\anaconda3\\envs\\py310_its530_agentsai\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\pnw_checkout\\anaconda3\\envs\\py310_its530_agentsai\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\pnw_checkout\\anaconda3\\envs\\py310_its530_agentsai\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\pnw_checkout\\anaconda3\\envs\\py310_its530_agentsai\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.5)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\pnw_checkout\\anaconda3\\envs\\py310_its530_agentsai\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\pnw_checkout\\anaconda3\\envs\\py310_its530_agentsai\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\pnw_checkout\\anaconda3\\envs\\py310_its530_agentsai\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\pnw_checkout\\anaconda3\\envs\\py310_its530_agentsai\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\pnw_checkout\\anaconda3\\envs\\py310_its530_agentsai\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\pnw_checkout\\anaconda3\\envs\\py310_its530_agentsai\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\pnw_checkout\\anaconda3\\envs\\py310_its530_agentsai\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\pnw_checkout\\anaconda3\\envs\\py310_its530_agentsai\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\pnw_checkout\\anaconda3\\envs\\py310_its530_agentsai\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\pnw_checkout\\anaconda3\\envs\\py310_its530_agentsai\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pnw_checkout\\anaconda3\\envs\\py310_its530_agentsai\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pnw_checkout\\anaconda3\\envs\\py310_its530_agentsai\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pnw_checkout\\anaconda3\\envs\\py310_its530_agentsai\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pnw_checkout\\anaconda3\\envs\\py310_its530_agentsai\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.12.14)\n",
      "Downloading sentence_transformers-3.4.1-py3-none-any.whl (275 kB)\n",
      "Installing collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-3.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06ae645e-a3e0-4723-a14e-cc6d9ec609ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textstat\n",
      "  Downloading textstat-0.7.5-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pyphen (from textstat)\n",
      "  Downloading pyphen-0.17.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting cmudict (from textstat)\n",
      "  Downloading cmudict-1.0.32-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\pnw_checkout\\anaconda3\\envs\\py310_its530_agentsai\\lib\\site-packages (from textstat) (75.8.0)\n",
      "Requirement already satisfied: importlib-metadata>=5 in c:\\users\\pnw_checkout\\anaconda3\\envs\\py310_its530_agentsai\\lib\\site-packages (from cmudict->textstat) (8.5.0)\n",
      "Requirement already satisfied: importlib-resources>=5 in c:\\users\\pnw_checkout\\anaconda3\\envs\\py310_its530_agentsai\\lib\\site-packages (from cmudict->textstat) (6.5.2)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\pnw_checkout\\anaconda3\\envs\\py310_its530_agentsai\\lib\\site-packages (from importlib-metadata>=5->cmudict->textstat) (3.21.0)\n",
      "Downloading textstat-0.7.5-py3-none-any.whl (105 kB)\n",
      "Downloading cmudict-1.0.32-py3-none-any.whl (939 kB)\n",
      "   ---------------------------------------- 0.0/939.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 939.4/939.4 kB 10.9 MB/s eta 0:00:00\n",
      "Downloading pyphen-0.17.2-py3-none-any.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ----------------------------------- ---- 1.8/2.1 MB 11.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 9.0 MB/s eta 0:00:00\n",
      "Installing collected packages: pyphen, cmudict, textstat\n",
      "Successfully installed cmudict-1.0.32 pyphen-0.17.2 textstat-0.7.5\n"
     ]
    }
   ],
   "source": [
    "!pip install textstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bed7d509-ad48-49ef-9518-9d6d97ee6bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from textstat import flesch_reading_ease\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cd542f4b-8873-4eb3-9c3b-564f34092ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61ea9eff8d5442c59731a855352adb97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PNW_checkout\\anaconda3\\envs\\py310_ITS530_AgentsAI\\lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\PNW_checkout\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2529bf6aa4884fbfa6ac7b9c9d6f63eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "588f1480b2b6459c9eb0b4fc8c5949bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eb38c21814b47f89e9940182af7681a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afc10da80b52474cba481206a704639a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "199fca410ac94a31a24bed7e7dd412b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fb708d3004f4c94b49ea8df0a48ce4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67471bfa2a244dc9b5f32985b3571dd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf8eb13784a042628d41afcc49656301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f551b240275a476dbac8a50d8798c48b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ac8b06e0ad644258baf99aea119bef4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "36dd7aab-3547-4841-ab96-bf6ada736b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embedding(text):\n",
    "    return embedding_model.encode(text, convert_to_numpy=True)\n",
    "\n",
    "def evaluate_relevance(results, known_gaps):\n",
    "    result_embeddings = np.array([generate_embedding(gap) for gap in results])\n",
    "    known_embeddings = np.array([generate_embedding(gap) for gap in known_gaps])\n",
    "\n",
    "    similarities = [\n",
    "        max(np.dot(result_emb, known_embeddings.T) / \n",
    "            (np.linalg.norm(result_emb) * np.linalg.norm(known_embeddings, axis=1))) \n",
    "        for result_emb in result_embeddings\n",
    "    ]\n",
    "    \n",
    "    return round(np.mean(similarities), 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "58e2406b-235a-4b78-b7a4-065a419c85fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_readability(results):\n",
    "    scores = [flesch_reading_ease(gap) for gap in results]\n",
    "    return round(np.mean(scores), 2)\n",
    "\n",
    "def calculate_precision_recall(results, true_gaps):\n",
    "    predicted = [1 if gap in true_gaps else 0 for gap in results]\n",
    "    actual = [1] * len(true_gaps) + [0] * (len(results) - len(true_gaps))\n",
    "    \n",
    "    precision = precision_score(actual, predicted, zero_division=1)\n",
    "    recall = recall_score(actual, predicted, zero_division=1)\n",
    "    \n",
    "    return round(precision, 2), round(recall, 2)\n",
    "\n",
    "def check_diversity(results):\n",
    "    unique_terms = set()\n",
    "    for gap in results:\n",
    "        unique_terms.update(gap.split())\n",
    "    \n",
    "    return round(len(unique_terms) / sum(len(gap.split()) for gap in results), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e6b22af6-6a29-48fb-8176-5d57f6ac89f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_gaps = [\"AI in supply chain risk management\", \n",
    "              \"Bias in predictive maintenance models\", \n",
    "              \"Data privacy in smart manufacturing\"]\n",
    "\n",
    "true_gaps = [\"AI in supply chain risk management\", \n",
    "             \"Bias in predictive maintenance models\"]\n",
    "\n",
    "results = [\"AI in supply chain risk management\", \n",
    "           \"Bias in predictive maintenance models\", \n",
    "           \"Blockchain applications in manufacturing\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9edd7281-ddae-45ca-bb12-b53b4def5547",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_eval_time = time.perf_counter()\n",
    "\n",
    "performance_metrics = {\n",
    "    \"Relevance Score\": evaluate_relevance(results, known_gaps),\n",
    "    \"Precision\": calculate_precision_recall(results, true_gaps)[0],\n",
    "    \"Recall\": calculate_precision_recall(results, true_gaps)[1],\n",
    "    \"Diversity Score\": check_diversity(results)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1169010c-6351-4095-8b6b-c12b91d2ccc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Performance Metrics:\n",
      "Relevance Score: 0.8299999833106995\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "Diversity Score: 0.87\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Performance Metrics:\")\n",
    "for metric, value in performance_metrics.items():\n",
    "    print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e2f710-d15a-43f2-a8e6-ea3b2305d4aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
